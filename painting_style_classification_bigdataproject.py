# -*- coding: utf-8 -*-
"""Painting_Style_Classification_BigDataProject.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1R3U0DVj6B9yhedV7UNggu4nlSajR5mW_

### Copyright 2020.#### 
**Author: H. Ngomseu Fotsing**

**Email: 217092052@student.uj.ac.za**

# Museum Artwork Image styles  Classification using CNN, VGG19 and SVM

In this notebook we will build on the model to classify 5 basic artwork styles(drawings, engraving, iconography, painting, sculpture) and improve accuracy by employing data augmentation

The Step in building are as follows:

1. Setting up libraries
2. Data collection and preprocessing.
3. Image classificaiton.
4. Loss and accuracy evaluation over the testing and training sets.
"""

#importig the tensorflow library for data classification
import tensorflow as tf

"""## 1. Setting up Libraries
Importing necessary libraries for computing the data
"""

#Importing libraries for data cleaning, segmentation and model classification
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.preprocessing.image import ImageDataGenerator



import keras
from keras import regularizers, optimizers
from keras.applications import VGG16, VGG19
from keras.models import Model, load_model, Sequential
from keras.layers import Dense, Activation, Flatten, Dropout
from keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing.image import array_to_img, img_to_array
from keras.preprocessing.image import load_img
from keras import backend as K
from keras.callbacks import ModelCheckpoint
from keras.wrappers.scikit_learn import KerasClassifier
from keras.utils import np_utils

import cv2
from IPython.display import Image, display
import pickle
import random
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

from PIL import Image
import os
import numpy as np
import matplotlib.pyplot as plt #For displaying the performance of the model

#installing the pyDrive library to access files from drive acount
!pip install -U -q PyDrive
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

#authenticating the drive account
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

#loading the zip dataset file from the drive
fid = drive.ListFile({'q':"title='Artwork_dataset.zip'"}).GetList()[0]['id']
f = drive.CreateFile({'id': fid})
f.GetContentFile('Artwork_dataset.zip')

f.keys()

"""## 2. Data Extraction
Here we extract the data from img_dsease ip file in our google drive storage
"""

#Extracting the images files(Unzipping)
!unzip Artwork_dataset.zip

PATH = 'dataset_updated'

os.listdir(PATH)

#settingup the path of the traning and testing dataset
train_dir = os.path.join(PATH, 'training_set')
validation_dir = os.path.join(PATH, 'validation_set')

def filterbadFile(folder_path):
  extensions = []
  for fldr in os.listdir(folder_path):
      sub_folder_path = os.path.join(folder_path, fldr)
      for filee in os.listdir(sub_folder_path):
          file_path = os.path.join(sub_folder_path, filee)
          print('** Path: {}  **'.format(file_path), end="\r", flush=True)
          im = Image.open(file_path)
          rgb_im = im.convert('RGB')
          if filee.split('.')[1] not in extensions:
              extensions.append(filee.split('.')[1])
  return extensions

train_drawings_dir = os.path.join(train_dir, 'drawings')  # directory with our training drawings pictures
train_engraving_dir = os.path.join(train_dir, 'engraving')  # directory with our training engraving pictures
train_iconography_dir = os.path.join(train_dir, 'iconography')  # directory with our training iconography pictures
train_painting_dir = os.path.join(train_dir, 'painting')  # directory with our training painting pictures
train_sculpture_dir = os.path.join(train_dir, 'sculpture')  # directory with our training painting pictures

valid_drawings_dir = os.path.join(validation_dir, 'drawings')  # directory with our valid drawings pictures
valid_engraving_dir = os.path.join(validation_dir, 'engraving')  # directory with our validation engraving pictures
valid_iconography_dir = os.path.join(validation_dir, 'iconography')  # directory with our validation iconography pictures
valid_painting_dir = os.path.join(validation_dir, 'painting')  # directory with our validation_ painting pictures
valid_sculpture_dir = os.path.join(validation_dir, 'sculpture')  # directory with our validation painting pictures

#validating the dataset by evaluating the number of images
#Training set
num_drawings_tr = len(os.listdir(train_drawings_dir))
num_engraving_tr = len(os.listdir(train_engraving_dir))
num_iconography_tr = len(os.listdir(train_iconography_dir))
num_painting_tr = len(os.listdir(train_painting_dir))
num_sculpture_tr = len(os.listdir(train_sculpture_dir))

#Testing set
num_drawings_val = len(os.listdir(valid_drawings_dir))
num_engraving_val = len(os.listdir(valid_engraving_dir))
num_iconography_val = len(os.listdir(valid_iconography_dir))
num_painting_val = len(os.listdir(valid_painting_dir))
num_sculpture_val = len(os.listdir(valid_sculpture_dir))

#Evaluating total for testing and training set
total_train = num_drawings_tr + num_engraving_tr + num_iconography_tr + num_painting_tr + num_sculpture_tr
total_val = num_drawings_val + num_engraving_val + num_iconography_val + num_painting_val + num_sculpture_val

#Displaying result
print('total training num_drawings_tr images:', num_drawings_tr)
print('total training num_engraving_tr images:', num_engraving_tr)
print('total training num_iconography_tr images:', num_iconography_tr)
print('total training num_painting_tr images:', num_painting_tr)
print('total training num_sculpture_tr images:', num_sculpture_tr)
print("--")

print('total validation num_drawings_tr images:', num_drawings_val)
print('total validation num_engraving_tr images:', num_engraving_val)
print('total validation num_iconography_tr images:', num_iconography_val)
print('total validation num_painting_tr images:', num_painting_val)
print('total validation num_sculpture_tr images:', num_sculpture_val)
print("--")
print("Total training images:", total_train)
print("Total validation images:", total_val)

"""###Data preprocessing
Rescaling data and storing in binary format for computation
"""

#Initialising the model dimensions
batch_size = 128
epochs = 15
IMG_HEIGHT = 150
IMG_WIDTH = 150

# Normalize pixel values to be between 0 and 1
train_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our training data
validation_image_generator = ImageDataGenerator(rescale=1./255) # Generator for our validation data

#Generating the training data from directory and formating it
train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                           directory=train_dir,
                                                           shuffle=True,
                                                           target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                           class_mode='binary')

print(train_data_gen)

#generating the testing dataset from testing directory
val_data_gen = validation_image_generator.flow_from_directory(batch_size=batch_size,
                                                              directory=validation_dir,
                                                              target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                              class_mode='binary')

#Storing the training images and it labels
sample_training_images, train_labels = next(train_data_gen)

"""## 3. Image Classification
We segment and label the training data that will be used for evaluation and testing
"""

#Displaying a sample output for 25 images with labels from the dataset
class_names = ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']

plt.figure(figsize=(10,10))
for i in range(25):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    plt.imshow(sample_training_images[i], cmap=plt.cm.binary)
    #plt.xlabel(str(train_labels[i]) + ': applescab')

    if(train_labels[i]==0.0):
      plt.xlabel(str(train_labels[i]) + ': drawings')
    elif(train_labels[i]==1.0):
      plt.xlabel(str(train_labels[i]) + ': engraving')
    elif(train_labels[i]==2.0):
      plt.xlabel(str(train_labels[i]) + ': iconography')
    elif(train_labels[i]==3.0):
      plt.xlabel(str(train_labels[i]) + ': painting')
    elif(train_labels[i]==4.0):
      plt.xlabel(str(train_labels[i]) + ': sculpture')
plt.show()

# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('on')
    plt.tight_layout()
    plt.show()

#Image segmentation
plotImages(sample_training_images[:5])

#setting up the model parameter with 3 convolutional layer and 3 denses
model = Sequential([
    Conv2D(32, (3, 3), input_shape=(IMG_HEIGHT, IMG_WIDTH, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.2),
    
    Conv2D(32, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.2),
    
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(pool_size=(2, 2)),
    Dropout(0.2),
    
    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.2),
    Dense(64, activation='relu'),
    Dropout(0.2),
    Dense(5, activation='softmax')
])

model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

#generating the model
history = model.fit_generator(
    train_data_gen,
    steps_per_epoch=total_train // batch_size,
    epochs=epochs,
    validation_data=val_data_gen,
    validation_steps=total_val // batch_size
)

"""## 4. Evaluating Loss and accuracy of training and Validation sets
Visual display of the performance, accuracy and loss using graphs
"""

import matplotlib.pyplot as plt
from google.colab import files

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(epochs)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Testing Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Testing Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Testing Loss')
plt.legend(loc='upper right')
plt.title('Training and Testing Loss')
plt.show()
plt.savefig('samplefigure1.png')
files.download('samplefigure1.png')

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')
plt.savefig('samplefigure.png')
files.download('samplefigure.png')

test_loss, test_acc = model.evaluate(sample_training_images,  train_labels, verbose=2)

print('Testing Accuracy: ' + str(test_acc))

"""Evaluating dataset using VGG19 network"""

# Load the VGG19 network
vgg_model = VGG19(include_top=False, weights='imagenet', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))
vgg_model.summary()

model = Sequential([
    vgg_model,
    Flatten(),
    Dense(64, activation='relu'),
    Dense(5, activation='softmax')
])

vgg_model.trainable = False

# Check what layers are trainable
for layer in model.layers:
    print(layer.name, layer.trainable)
    
#model.summary()

# Compilation
model.compile(optimizer='adam',
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])
# Fitting the Model
train_result = model.fit_generator(
            train_data_gen,
            steps_per_epoch=total_train // batch_size,
            epochs=epochs,
            validation_data=val_data_gen,
            validation_steps=total_val // batch_size
            )

model.save('VGG19_Feature.h5')

import seaborn as sns

sns.set(style="white", palette="muted", color_codes=True)

fig, ax = plt.subplots(1, 2, figsize=(16, 6), sharex=True)

ax[0].plot(train_result.history['loss'], label="Loss")
ax[0].plot(train_result.history['val_loss'], label="Validation loss")
ax[0].set_title('Loss')
ax[0].set_xlabel('Epoch')
ax[0].set_ylabel('Loss')
ax[0].legend()

ax[1].plot(train_result.history['accuracy'], label="Accuracy")
ax[1].plot(train_result.history['val_accuracy'], label="Validation accuracy")
ax[1].set_title('Accuracy')
ax[1].set_xlabel('Epoch')
ax[1].set_ylabel('Accuracy')
ax[1].legend()
plt.tight_layout()

plt.show();

"""Pipeline 2: Classificaiton using SVM

Visual display of the performance, accuracy and loss using graphs
"""

dir = train_dir
categories = ['drawings', 'engraving', 'iconography', 'painting', 'sculpture']
data = []

for category in categories:
  path = os.path.join(dir, category)
  label = categories.index(category)
  for img in os.listdir(path):
    imgpath = os.path.join(path,img)
    paint_img = cv2.imread(imgpath, 0)
    #display(Image(imgpath, width=300, height=200))
    try:
      paint_img = cv2.resize(paint_img, (50,50))
      image = np.array(paint_img).flatten()
      data.append([image, label])
    except Exception as e:
      pass

print(len(data))

pick_in = open('data1.pickle', 'wb')
pickle.dump(data, pick_in)
pick_in.close()

pick_in = open('data1.pickle', 'rb')
data = pickle.load(pick_in)
pick_in.close()

random.shuffle(data)
features = []
labels = []

for feature, label in data:
  features.append(feature)
  labels.append(label)

xtrain, xtest, ytrain, ytest = train_test_split(features, labels, test_size = 0.25)

model = SVC(C=1, kernel='linear', probability=True, gamma='auto')
probas_ = model.fit(xtrain, ytrain).predict_proba(xtest)

prediction = model.predict(xtest)
accuracy = model.score(xtest, ytest)

print('Accuracy: ', accuracy)
print('Prediction is : ', categories[prediction[0]])

mypaint = xtest[0].reshape(50,50)
#display(Image(mypaint, width=300, height=200))
plt.imshow(mypaint, cmap='gray')
plt.show()

pick = open('model.sav', 'wb')
pickle.dump(model, pick)
pick.close()

pick = open('model.sav', 'rb')
pickle.load(pick)
pick.close()

# packages to import


import numpy as np
import pylab as pl
from sklearn import svm
from sklearn.utils import shuffle
import sklearn.metrics as metrics

from sklearn.metrics import roc_curve, auc
random_state = np.random.RandomState(0)

# Compute ROC curve and area the curve
fpr, tpr, thresholds = roc_curve(ytest, probas_[:, 1])
roc_auc = auc(fpr, tpr)
print("Area under the ROC curve : %f" % roc_auc)

# Plot ROC curve
pl.clf()
pl.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)
pl.plot([0, 1], [0, 1], 'k--')
pl.xlim([0.0, 1.0])
pl.ylim([0.0, 1.0])
pl.xlabel('False Positive Rate')
pl.ylabel('True Positive Rate')
pl.title('Receiverrating characteristic example')
pl.legend(loc="lower right")
pl.show()